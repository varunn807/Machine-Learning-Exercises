{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees\n",
    "\n",
    "\n",
    "Here, we will use decision trees for classification of Iris species (Setosa, Versicolor, Virginica). Use random_state=0 for splitting and building all models.\n",
    "\n",
    "#### 1) Fit decision tree with maximum depth (max_depth) of 2 and the default gini index for building the tree. Find the classification accuracy. (3pts)\n",
    "\n",
    "- Visualize the tree as follows (optional). First, import the graphviz package from terminal using the following:\n",
    "\n",
    "brew install graphviz\n",
    "\n",
    "OR\n",
    "\n",
    "#conda install -c anaconda graphviz  \n",
    "#conda install -c anaconda python-graphviz \n",
    "\n",
    "Then, use can use the package to visulaize the decision tree as follows: \n",
    "        \n",
    "        from sklearn.tree import export_graphviz\n",
    "        import graphviz \n",
    "        \n",
    "     dot_data=export_graphviz(FittedTreeModel,class_names=iris_dataset.target_names,   feature_names=iris_dataset.feature_names,out_file=None)\n",
    "        \n",
    "       graph = graphviz.Source(dot_data)  \n",
    "       graph \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data=load_iris()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data['data'],data['target'],random_state=0)\n",
    "treeModel=DecisionTreeClassifier(max_depth=2)\n",
    "treeModel.fit(X_train,Y_train)\n",
    "accuracy=treeModel.score(X_test,Y_test)\n",
    "print(\"Accuracy of the model is :\",accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Use random forests to classify the Iris species. The random forests combines 4 decision trees, each of maximum depth 2 and maximum number of features considered at each split is 2. What is the classification accuracy? (3pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "forestModel= RandomForestClassifier(n_estimators=4, max_features=2, max_depth=2, random_state=0) \n",
    "forestModel.fit(X_train,Y_train)\n",
    "accuracyR=forestModel.score(X_test,Y_test)\n",
    "print(\"Accuracy of the model is :\",accuracyR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use AdaBoost with 4 decision tree models to perform the classification of the Iris species. What is the accuracy? Comment on results. (3pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is : 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "BoostModel= AdaBoostClassifier(n_estimators=4)\n",
    "BoostModel.fit(X_train,Y_train)\n",
    "accuracyB=BoostModel.score(X_test,Y_test)\n",
    "print(\"Accuracy of the model is :\",accuracyB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of AdaBoost is highest.This is because in AdaBoost each subsequent learner if stronger than it's previous learner and 4 estimators gives the best accuracy.Increasing or decreasing the number of estimators reduces accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Neural networks (multilayer perceptron) to classify the Iris species, Build a model that has two hidden layers, the first layer has 10 neurons and second layer has 5 neurons. Use 'tanh' activation function, and set the regularization parameter alpha=0.5. Scale the feautures with MinMaxScaler. Try the following settings (a)-(c) and report the accuracy, then comment on the results.\n",
    "\n",
    "a) Use gradient descent to solve the optimization  problem (i.e. get the weights), and choose random_state=0 (which corresponds to a particular initializationo of weight values), and set max_iter=5000. Print the accuracy. (3pts)\n",
    "   \n",
    "b) Repeat (a) above but with a model that uses random_state=10 to initialize the weights. Print the accuracy. (2pts)\n",
    "    \n",
    "    \n",
    "c) Repeat (b) but with model that use L-BFGS (a numerical quasi-Newton method of optimization) instead of stochastic gradient descent to find the weights. Print the accuracy (3pts)\n",
    "    \n",
    "d) Comment on results (3pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of when gradient descent is used :  0.9473684210526315\n",
      "Accuracy of when gradient descent is used :  0.9210526315789473\n",
      "Accuracy of when gradient descent is used :  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler=preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_transformed=scaler.transform(X_train)\n",
    "X_test_transformed=scaler.transform(X_test)\n",
    "\n",
    "MLPmodel=MLPClassifier(solver='sgd', activation='tanh', random_state=0, hidden_layer_sizes=[10,5], alpha=0.5,max_iter=5000).fit(X_train_transformed,Y_train)\n",
    "\n",
    "accuracy=MLPmodel.score(X_test_transformed,Y_test)\n",
    "print(\"a) Accuracy of model when gradient descent is used : \",accuracy)\n",
    "\n",
    "MLPmodel=MLPClassifier(solver='sgd', activation='tanh', random_state=10, hidden_layer_sizes=[10,5], alpha=0.5,max_iter=5000).fit(X_train_transformed,Y_train)\n",
    "\n",
    "accuracy=MLPmodel.score(X_test_transformed,Y_test)\n",
    "print(\"b) Accuracy of model when gradient descent with random state(10) is used : \",accuracy)\n",
    "\n",
    "MLPmodel=MLPClassifier(solver='lbfgs', activation='tanh', random_state=10, hidden_layer_sizes=[10,5], alpha=0.5,max_iter=5000).fit(X_train_transformed,Y_train)\n",
    "\n",
    "accuracy=MLPmodel.score(X_test_transformed,Y_test)\n",
    "print(\"c) Accuracy of model when quasi-Newton method  is used : \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Accuracy is highest for quasi-Newton method.It may be due to the fact that the iris datset is relatively small(50 data samples) and quasi-Newton method  works better with small datsets.In case of gradient descent, random state value of 0 gives better accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
